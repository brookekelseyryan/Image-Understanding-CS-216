{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS216 : Assignment 2\n",
    "\n",
    "Reading: Review your class notes, Klette Chapter 1.2-1.3,\n",
    "Szeliski Chapter 2,3 and/or Forsyth and Ponce Chapters 1,4,8,9\n",
    "\n",
    "For written problems, you can either use Markdown/LaTeX to directly enter your reponse in the provided notebook cell, or if you prefer, write out by hand and embed a photo of your solution. For coding problems, I have provided some suggestion of how to structure your code but feel free to modify or ignore as you see fit.\n",
    "\n",
    "Please edit the cell below to include your name and student ID #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**name:**\n",
    "\n",
    "**SID:**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from numpy import fft\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Convolution versus Correlation\n",
    "\n",
    "Prove that *convolution* is associative, that is  $(f \\star g) \\star h = f \\star (g \\star h)$\n",
    "\n",
    "Prove that *correlation* is not associative (best done by showing a counter-example)\n",
    "\n",
    "You should just show this for discrete 1D signals and assume the signal has been extended periodically as we did in lecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fast Fourier Transform\n",
    "\n",
    "If we have an image $I$ of dimension $H$x$W$ and we convolve it with a\n",
    "filter $f$ of size $M$x$N$ using the spatial domain formula given in class,\n",
    "what will the complexity be (i.e. how many multiplications)?  How about if we\n",
    "use the [Fast Fourier Transform](https://en.wikipedia.org/wiki/Fast_Fourier_transform) \"trick\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Factorizing Filters\n",
    "Starting with the formula for 2D convolution, show that if our filter is\n",
    "the product of two functions, $f(x,y)=f_1(x)f_2(y)$, we can compute the\n",
    "convolution more efficiently.  Is there a way to use this idea to speed up\n",
    "convlution with a 2D isotropic Gaussian filter $g(x,y) = \\frac{1}{2\\pi\\sigma^2}\n",
    "\\exp^{\\frac{-(x^2 + y^2)}{2 \\sigma^2}}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experimenting with the DFT\n",
    "\n",
    "Import the appropriate functions from the numpy [fft module](https://numpy.org/doc/stable/reference/routines.fft.html) and carry out some experiments yourself. You will want to use the ***fftshift*** function to get the spectra like we showed in class where 0 is at the center\n",
    "\n",
    "**4.1** Start out in 1D and make a signal which is of length 100 with a single\n",
    "impulse of height 1 in the middle.  Compute the DFT of the signal and plot the\n",
    "magnitude of the spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2** Now increase the width of the pulse from a single sample to a unit height\n",
    "``box function'' 5 and 10 samples long and plot resulting the spectrum\n",
    "magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3** Now do the same for a Gaussian function with $\\sigma = 1$\n",
    "and $\\sigma = 2$ (the Gaussian has infinite support but you should just analyze\n",
    "a finite chunk centered around the origin)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.4** Figure out how to do a 2D DFT and inverse DFT.  Replicate the experiment we showed in class (shown as\n",
    "Figure 7.6 in Forsyth and Ponce) of swapping phase and magnitude by (1) computing the DFT of two images of the same size, (2) computing a new set of coefficents which have the phase from the first image and the mangitude from\n",
    "the second image, (3) taking the inverse DFT of this combined spectrum to produce a new image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Edge Detection\n",
    "\n",
    "Write a gradient based edge detector.  Your code should load in\n",
    "an image and convert to grayscale floats.  Once you have loaded in the image, \n",
    "you should smooth the image with a\n",
    "Gaussian filter and then compute horizontal and vertical derivatives using the\n",
    "derivative filter described in lecture.  The amount of smoothing is determined\n",
    "by the $\\sigma$ of the Gaussian (which should be a parameter of your code).\n",
    "You can use **scipy.ndimage.convolve2d** option to perform the required\n",
    "convolutions. Once you have computed the derivatives in the $x$ and $y$\n",
    "directions using convolution, compute the gradient magnitude and angle\n",
    "and threshold the magnitude to find the edge pixels. To do non-maximum \n",
    "suppression, you can use **skimage.morphology.thin** in order\n",
    "to get out a 1-pixel-wide version of the detected edges.\n",
    "\n",
    "### 5.1 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# suggestion on how to structure your code... feel free to\n",
    "# modify or ignore as you see fit\n",
    "#\n",
    "\n",
    "def image_gradient(I,sigma):\n",
    "    \"\"\"\n",
    "    Compute the gradient orientation and magnitude after\n",
    "    smoothing I with a Gaussian filter with parameter sigma\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def detect_edge(I,sigma,thresh):\n",
    "    \"\"\"\n",
    "    Detect edges in an image using the given smoothing and threshold\n",
    "    parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Demonstration\n",
    "\n",
    "For two images (the synthetic example below and an additional image of your choice), visualize the input image, gradient magnitude, angle and the edge detection output for two different settings of $\\sigma$. This will yield 16 images in total. You should make sure that the image is low enough resolution and the plots large enough to clearly see the results. For visualizing the orientation, you should use a circular colormap such as \"twilight\" or \"hsv\". You should include colorbars on your plots where appropriate so the range of values is visible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the plot figure size\n",
    "plt.rcParams['figure.figsize'] = (12,12)\n",
    "\n",
    "# synthetic test image for debugging purposes\n",
    "[yy,xx] = np.mgrid[-100:100,-100:100]\n",
    "image = np.minimum(np.maximum(np.array(xx*xx+yy*yy,dtype=float),400),8100)\n",
    "\n",
    ".\n",
    ".\n",
    ".\n",
    ".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Template Detection\n",
    "\n",
    "Implement a simple object detector based on cross-correlation.  Load in one\n",
    "of the test images provided and display it on the screen.  Clip out a patch\n",
    "of the image containing an object you want to detect.  Use this patch as a template\n",
    "in order to try and detect other instances of the object in the image.\n",
    "\n",
    "You should implement three different variants for computing a match score $S$\n",
    "between the template $T$ and the image $I$. \n",
    "\n",
    "1. Cross-correlation (CC): \n",
    "\n",
    "  $S(x,y) = \\sum_{i,j} T[i,j]I[x+i,y+j]$\n",
    "\n",
    "\n",
    "2. Normalized Cross-correlation (NCC): \n",
    "\n",
    "  $S(x,y) = \\sum_{i,j} \\frac{(T[i,j]-\\mu_T)}{\\sigma_T}\\frac{(I[x+i,y+j]-\\mu_{xy})}{\\sigma_{xy}}$\n",
    "\n",
    "  $\\mu_{xy} = \\frac{1}{N}\\sum_{i,j} I[x+i,y+j]$\n",
    "\n",
    "  $\\sigma_{xy} = \\sqrt{\\frac{1}{N}\\sum_{i,j} (I[x+i,y+j]-\\mu_{xy})^2}$\n",
    "\n",
    "\n",
    "3. Sum-of-squared-differences (SSD): \n",
    "\n",
    "  $S(x,y) = -\\sum_{i,j} (T[i,j] - I[x+i,y+j])^2$\n",
    "\n",
    "Note, I've added a minus sign in front of SSD to make it consistent with the other two \n",
    "so that a larger score $S$ corresponds to a better match.\n",
    "\n",
    "You can implement all of these quite effeciently using a couple convolutions and \n",
    "vectorized NumPy operations. If you use convolution to perform cross-correlation, \n",
    "don't forget to flip the template left-right and top-bottom. To compute averages,\n",
    "you can use convolution with a filter of all 1s the same size as your template.\n",
    "\n",
    "You can try thresholding the resulting score map $S$ but you will note that\n",
    "around detected objects there will be many pixels with high values.  In order to\n",
    "suppress non-maximal responses, zero out any locations which are smaller than one\n",
    "of their 8 neighbors. You can do this effeciently in NumPy using array indexing, \n",
    "e.g. in 1D this might look like:\n",
    "\n",
    "$$\n",
    "L = x[1:-1] > x[0:-2]   #bigger than our neighbor to the left?\n",
    "R = x[1:-1] > x[2:]     #bigger than our neighbor to the right?\n",
    "T = x[1:-1] > threshold #above detection threshold?\n",
    "maxima = R & L & T\n",
    "$$\n",
    "\n",
    "It is also probably a good idea to set an upper limit on the number of detections your\n",
    "function returns (e.g., so if you happen to call it with too low a threshold things\n",
    "don't get overly slow).\n",
    "\n",
    "### 6.1 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# suggestion on how to structure your code... feel free to\n",
    "# ignore or modify as you see fit\n",
    "#\n",
    "\n",
    "def detect_template(I,template,thresh,method):\n",
    "    \"\"\"\n",
    "    Detect a object in an image by performing cross-correlation with the\n",
    "    supplied template\n",
    "    \n",
    "    image : 2D float array of shape HxW\n",
    "         An array containing pixel brightness values\n",
    "    \n",
    "    template : 2D float array \n",
    "         Template we wish to match.\n",
    "         \n",
    "    thresh : float\n",
    "        Score threshold above which we declare a positive match\n",
    "\n",
    "    method : one of {'cc','ncc','ssd'}\n",
    "        Method for comparing template and image patch\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    detections : a list of tuples of length ndetect\n",
    "        Each detection is a tuple (x,y,score)\n",
    "    \n",
    "    heatmap : detection score map prior to non-max suppression\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    #\n",
    "    # some example code for finding the top scoring locations\n",
    "    # stored in some 2D array \n",
    "    #\n",
    "    # sort the values in resp in ascending order.\n",
    "    # val[i] should be ith largest score in resp\n",
    "    # ind[i] should be the index at which it occurred so that val[i]==resp[ind[i]]\n",
    "    # \n",
    "    val = np.sort(resp, axis=None)[::-1] # sorted response values\n",
    "    ind = np.argsort(resp, axis=None)[::-1]  #corresponding indices\n",
    "    \n",
    "    # recover the x,y coordinates of the ith largest response\n",
    "    [y,x] = np.unravel_index(ind[i], resp.shape)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Visualization and Discussion\n",
    "\n",
    "Initially experiment with choosing a relatively small \"object\" such as Dilbert's nose or a \n",
    "single letter as your template. You can use the provided images but you should also experiment\n",
    "with some image of your own choosing (ideally which contains more than one instance of the \n",
    "object of interest).\n",
    "\n",
    "Plot the locations of above threshold local maxima on top of the original image using \n",
    "**patches.Rectangle**.  Experiment with the threshold to try to find a good tradeoff between \n",
    "detecting all the instances of an object and but not too many background detections.  Show \n",
    "a visualization of the template you used, the cross-correlation output using a false colormap \n",
    "(e.g. \"jet\"), and your final detection results.\n",
    "\n",
    "Compare outputs of the three different methods (cc,ncc,ssd). You'll need to choose a different\n",
    "threshold for each one. Discuss briefly which one appears to work the best and come up with \n",
    "an explanation as to why you think this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some results\n",
    "\n",
    "#\n",
    "# example code for visualizing detections\n",
    "#\n",
    "plt.imshow(image,cmap=plt.cm.gray)\n",
    "ax = plt.gca()\n",
    "w = tsize_pix[1] #size of the template\n",
    "h = tsize_pix[0] \n",
    "ct = 0\n",
    "for (x,y,score) in detections:\n",
    "    xc = x-(w//2)\n",
    "    yc = y-(h//2)\n",
    "    rect = patches.Rectangle((xc,yc),w,h,linewidth=2,edgecolor=np.array([1,0,0]),facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    ct = ct + 1\n",
    "plt.show()\n",
    "\n",
    ".\n",
    ".\n",
    ".\n",
    ".\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***your discussion of results goes here***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
